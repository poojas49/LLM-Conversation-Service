ollama {
  host = "http://localhost:11434"
  model = "llama2:latest"
  request-timeout-seconds = 500
}

service {
  host = "localhost"
  port = 8080
}

conversation {
  max-turns = 5
  timeout-minutes = 30
}
